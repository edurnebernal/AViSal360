# AViSal360: Audiovisual Saliency Prediction for 360º Video

Code and models for *“AViSal360: Audiovisual Saliency Prediction for 360º Video”* ([PDF](https://graphics.unizar.es/papers/ISMAR2024_AViSal360.pdf))


Edurne Bernal-Berdun, Jorge Pina, Mateo Vallejo, Ana Serrano, Daniel Martin, and Belen Masia

**ISMAR 2024**

## Abstract
Saliency prediction in 360º video plays an important role in modeling visual attention, and can be leveraged for content creation, compression techniques, or quality assessment methods, among others. Visual attention in immersive environments depends not only on visual input, but also on inputs from other sensory modalities, primarily audio. Despite this, only a minority of saliency prediction models have incorporated auditory inputs, and much remains to be explored about what auditory information is relevant and how to integrate it in the prediction. In this work, we propose an audiovisual saliency model for 360º video content, AViSal360. Our model integrates both spatialized and semantic audio information, together with visual inputs. We perform exhaustive comparisons to demonstrate both the actual relevance of auditory information in saliency prediction, and the superior performance of our model when compared to previous approaches.

Visit our [website](https://graphics.unizar.es/projects/AViSal360_2024/) for more information and supplementary material.
